=import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import tkinter as tk
from tkinter import ttk
from PIL import Image, ImageDraw
from torchvision import datasets, transforms
import threading
import queue
import os
import time

# ==========================================
# 1. å·¥ç¨‹é…ç½® (Configuration)
# ==========================================
class Config:
    # --- ç½‘ç»œè§„æ¨¡ ---
    NODE_COUNT = 800        # æ€»èŠ‚ç‚¹æ•°
    NEIGHBOR_K = 40         # ç¨€ç–åº¦ï¼šæ¯ä¸ªèŠ‚ç‚¹åªè¿æ¥æœ€è¿‘çš„ K ä¸ª
    INPUT_RATIO = 0.25      
    OUTPUT_COUNT = 10       
    
    # --- ç‰©ç†ä¸å‡ ä½• ---
    RADIUS = 1.6            
    PHYSICS_DT = 0.5        # ç‰©ç†æ—¶é—´æ­¥é•¿
    FORCE_REPULSION = 0.04  # æ–¥åŠ›
    FORCE_SPRING = 0.12     # å¼¹ç°§åŠ›
    FORCE_ANCHOR = 0.05     # é”šç‚¹åŠ›
    
    # --- è®­ç»ƒè¶…å‚ ---
    EPOCHS = 50             
    BATCH_SIZE = 128
    LR = 0.005
    PROPAGATION_STEPS = 12  # æ¨ç†æ—¶çš„ä¿¡å·ä¼ æ’­æ­¥æ•°
    
    # --- ç³»ç»Ÿ ---
    RENDER_FPS = 30         # UI åˆ·æ–°ç‡é™åˆ¶
    SAVE_DIR = "./models_engineering"
    MODEL_NAME = "snn_sparse_tensor.pth"
    
    # --- è®¾å¤‡ ---
    if torch.backends.mps.is_available():
        DEVICE = torch.device("mps")
        print("ğŸš€ Backend: Apple MPS (Metal)")
    elif torch.cuda.is_available():
        DEVICE = torch.device("cuda")
        print("ğŸš€ Backend: NVIDIA CUDA")
    else:
        DEVICE = torch.device("cpu")

    # --- é¢œè‰² ---
    THEME_BG = '#0b0b0b'
    COLOR_NODE = '#444444'
    COLOR_IN = '#00ff00'
    COLOR_OUT = '#ff0055'

if not os.path.exists(Config.SAVE_DIR): os.makedirs(Config.SAVE_DIR)

# ==========================================
# 2. ç¨€ç–å¼ é‡å›¾ç½‘ç»œ (Sparse Tensor SNN)
# ==========================================
class SparseSNN(nn.Module):
    def __init__(self):
        super().__init__()
        
        N = Config.NODE_COUNT
        K = Config.NEIGHBOR_K
        
        # 1. ç‰©ç†ä½ç½® (N, 2) - Parameter ä½†æ‰‹åŠ¨æ›´æ–°
        self.pos = nn.Parameter(torch.zeros(N, 2, device=Config.DEVICE), requires_grad=False)
        self._init_geometry()
        
        # 2. æ‹“æ‰‘ç»“æ„ (N, K) - å­˜å‚¨æ¯ä¸ªèŠ‚ç‚¹è¿æ¥çš„é‚»å±…ç´¢å¼•
        # æˆ‘ä»¬ä½¿ç”¨ buffer å› ä¸ºå®ƒä¸æ˜¯æ¢¯åº¦å‚æ•°ï¼Œæ˜¯çŠ¶æ€
        self.register_buffer('indices', torch.zeros(N, K, dtype=torch.long, device=Config.DEVICE))
        
        # 3. è¿æ¥æƒé‡ (N, K) - è¿™æ˜¯å¯è®­ç»ƒå‚æ•°
        # å¯¹åº” indices ä¸­çš„è¿æ¥å¼ºåº¦
        self.weights = nn.Parameter(torch.randn(N, K, device=Config.DEVICE) * 0.05)
        
        # 4. ç¥ç»å…ƒåç½® (N)
        self.bias = nn.Parameter(torch.zeros(N, device=Config.DEVICE))
        
        # 5. è¾…åŠ©å˜é‡ï¼šInput/Output ç´¢å¼•
        self._setup_io_indices()
        
        # åˆå§‹åŒ–è¿æ¥
        self.update_topology(force_reset=True)

    def _init_geometry(self):
        """åˆå§‹åŒ–åœ†å½¢åˆ†å¸ƒ"""
        r = Config.RADIUS
        # æåæ ‡éšæœºç”Ÿæˆ
        theta = torch.rand(Config.NODE_COUNT, device=Config.DEVICE) * 2 * np.pi
        rad = r * torch.sqrt(torch.rand(Config.NODE_COUNT, device=Config.DEVICE))
        
        with torch.no_grad():
            self.pos[:, 0] = rad * torch.cos(theta)
            self.pos[:, 1] = rad * torch.sin(theta)

    def _setup_io_indices(self):
        """å®šä¹‰ I/O èŠ‚ç‚¹ç´¢å¼•"""
        x = self.pos[:, 0]
        # æ’åº X è½´
        sorted_idx = torch.argsort(x)
        
        n_in = int(Config.NODE_COUNT * Config.INPUT_RATIO)
        self.input_idx = sorted_idx[:n_in]
        self.output_idx = sorted_idx[-Config.OUTPUT_COUNT:]
        
        # é”šç‚¹ç›®æ ‡ä½ç½® (ç”¨äºç‰©ç†ç‰µå¼•)
        self.register_buffer('anchor_pos', self.pos.clone())
        # Input é”šç‚¹åœ¨å·¦ï¼ŒOutput åœ¨å³
        self.anchor_pos[self.input_idx, 0] = -Config.RADIUS * 0.8
        self.anchor_pos[self.output_idx, 0] = Config.RADIUS * 0.8
        
        # æ©ç ï¼šå“ªäº›èŠ‚ç‚¹å—é”šç‚¹åŠ›å½±å“
        self.register_buffer('anchor_mask', torch.zeros(Config.NODE_COUNT, 1, device=Config.DEVICE))
        self.anchor_mask[self.input_idx] = 1.0
        self.anchor_mask[self.output_idx] = 1.0

    def update_topology(self, force_reset=False):
        """
        æ ¸å¿ƒå·¥ç¨‹ä¼˜åŒ–ï¼šåŸºäº TopK æ›´æ–°è¿æ¥ã€‚
        ä¸ºäº†ä¿æŒè¿›åŒ–çš„â€œè¿ç»­æ€§â€ï¼Œæˆ‘ä»¬ä¸ä»…è¦ç®—è·ç¦»ï¼Œè¿˜è¦å°è¯•ä¿ç•™æƒé‡ã€‚
        """
        with torch.no_grad():
            N, K = Config.NODE_COUNT, Config.NEIGHBOR_K
            
            # 1. è®¡ç®—å…¨è·ç¦»çŸ©é˜µ (N, N)
            # å¯¹äº N=800ï¼Œè¿™æ˜¯æå…¶å¿«é€Ÿçš„ GPU æ“ä½œ
            dists = torch.cdist(self.pos, self.pos)
            
            # 2. æ‰¾åˆ°æœ€è¿‘çš„ K ä¸ªé‚»å±… (N, K)
            # largest=False å–æœ€å°è·ç¦»
            vals, new_indices = dists.topk(K + 1, largest=False) 
            # æ’é™¤è‡ªå·± (ç¬¬0ä¸ªé€šå¸¸æ˜¯è‡ªå·±ï¼Œè·ç¦»ä¸º0)
            new_indices = new_indices[:, 1:] 
            
            if force_reset:
                self.indices.copy_(new_indices)
                nn.init.orthogonal_(self.weights, gain=0.1)
                return

            # 3. æƒé‡è¿ç§» (Weight Migration) - å…³é”®æ­¥éª¤
            # æˆ‘ä»¬éœ€è¦æŠŠæ—§ weights æ˜ å°„åˆ°æ–° indices ä¸Šã€‚
            # å¦‚æœæ–°é‚»å±… j ä»¥å‰ä¹Ÿæ˜¯é‚»å±…ï¼Œä¿ç•™æƒé‡ï¼›å¦‚æœæ˜¯æ–°é¢å­”ï¼Œåˆå§‹åŒ–ä¸ºå°å€¼ã€‚
            
            # è¿™æ˜¯ä¸€ä¸ªé«˜ç»´ Gather/Scatter é—®é¢˜ï¼Œä¸ºäº†æ€§èƒ½ï¼Œæˆ‘ä»¬ç®€åŒ–å¤„ç†ï¼š
            # æ—¢ç„¶æ˜¯â€œæ¸©æŸ”è¿›åŒ–â€ï¼Œå¤§éƒ¨åˆ† indices æ˜¯ä¸ä¼šå˜çš„ã€‚
            # æˆ‘ä»¬ç›´æ¥æ¯”è¾ƒ indices å·®å¼‚ä¸å¤ªå®¹æ˜“å¹¶è¡ŒåŒ–ã€‚
            
            # ã€å·¥ç¨‹å¦¥åæ–¹æ¡ˆã€‘ï¼š
            # æˆ‘ä»¬å‡è®¾æ¯ä¸€è½®ä½ç§»å¾ˆå°ï¼ŒTopK çš„å˜åŒ–ä¸»è¦å‘ç”Ÿåœ¨è¾¹ç¼˜ã€‚
            # æˆ‘ä»¬åªå¯¹â€œå…¨æ–°â€çš„è¿æ¥è¿›è¡Œé™æƒï¼Œå…¶ä»–ä½ç½®ä¿ç•™åŸ Tensor çš„æ•°å€¼ï¼ˆå³ç»§æ‰¿äº†è¯¥ Slot çš„æƒé‡ï¼‰ã€‚
            # è™½ç„¶è¿™åœ¨æ•°å­¦ä¸Šä¸ä¸¥æ ¼ï¼ˆSlot 0 çš„é‚»å±…å¯èƒ½æ¢äººäº†ï¼‰ï¼Œä½†ä»ç»Ÿè®¡å­¦ä¸Šï¼Œ
            # è¿™ç§éšæœºæ‰°åŠ¨åè€Œæœ‰åŠ©äºè·³å‡ºå±€éƒ¨æœ€ä¼˜ï¼Œä¸”é¿å…äº†å¤æ‚çš„ Hash Map æ“ä½œã€‚
            
            # æ£€æµ‹ maskï¼šå¦‚æœè·ç¦»çªç„¶å˜è¿œäº†ï¼ˆè¯´æ˜æ‹“æ‰‘å‰§çƒˆå˜åŒ–ï¼‰ï¼Œå¯ä»¥é‡ç½®
            # è¿™é‡Œæˆ‘ä»¬ç®€å•åœ°ï¼š
            # å¯¹ indices ç›´æ¥è¦†ç›–
            self.indices.copy_(new_indices)
            
            # å¯¹ weights è¿›è¡Œè¡°å‡ (Weight Decay)ï¼Œæ¨¡æ‹Ÿé—å¿˜
            self.weights.mul_(0.99) 
            
            # å¼•å…¥å°‘é‡å™ªå£°ï¼Œæ¿€æ´»æ–°è¿æ¥
            self.weights.add_(torch.randn_like(self.weights) * 0.002)

    def physics_step(self):
        """
        åŸºäº Tensor çš„çŸ¢é‡åŒ–ç‰©ç†å¼•æ“
        """
        with torch.no_grad():
            N = Config.NODE_COUNT
            
            # 1. è®¡ç®—æ–¥åŠ› (Repulsion) - è¿‘é‚»é‡‡æ ·ä¼˜åŒ–
            # ä¸ºäº†ä¸ç”¨ N^2ï¼Œæˆ‘ä»¬åªè®¡ç®— TopK é‚»å±…çš„æ–¥åŠ› (è¿‘ä¼¼)
            # æˆ‘ä»¬åˆ©ç”¨ self.indices é‡Œçš„é‚»å±…è®¡ç®—æ–¥åŠ›ï¼Œè¿™æ¯”å…¨å±€ N^2 å¿«å¾ˆå¤š
            
            # Gather neighbor positions: (N, K, 2)
            # self.pos: (N, 2)
            # self.indices: (N, K)
            # å±•å¼€ç´¢å¼•ä»¥é€‚åº” gather: (N, K, 2)
            idx_exp = self.indices.unsqueeze(-1).expand(-1, -1, 2)
            neighbor_pos = torch.gather(self.pos.unsqueeze(1).expand(-1, Config.NEIGHBOR_K, -1), 0, idx_exp)
            
            # Delta: (N, K, 2)
            delta = self.pos.unsqueeze(1) - neighbor_pos
            dist_sq = (delta ** 2).sum(dim=2, keepdim=True) + 0.1 # (N, K, 1)
            
            # F_rep = k / dist^2 * dir
            force_rep = torch.sum(delta * (Config.FORCE_REPULSION / dist_sq), dim=1) # (N, 2)
            
            # 2. è®¡ç®—å¼¹ç°§åŠ› (Spring) - åªé’ˆå¯¹æœ‰è¿æ¥çš„
            # F_spring = k * dist * weight
            # æƒé‡è¶Šå¤§ï¼Œæ‹‰åŠ›è¶Šå¤§
            w_abs = self.weights.abs().unsqueeze(-1) # (N, K, 1)
            force_spring = torch.sum(-delta * w_abs * Config.FORCE_SPRING, dim=1)
            
            # 3. é”šç‚¹åŠ› (Anchor) - è®© IO å½’ä½
            force_anchor = (self.anchor_pos - self.pos) * self.anchor_mask * Config.FORCE_ANCHOR
            
            # 4. å…¨å±€å‘å¿ƒåŠ› (Centering) - é˜²æ­¢å‘æ•£
            force_center = -self.pos * 0.01
            
            # æ›´æ–°ä½ç½®
            total_force = force_rep + force_spring + force_anchor + force_center
            
            # é™åˆ¶æœ€å¤§é€Ÿåº¦ (Clipping)
            total_force = torch.clamp(total_force, -0.1, 0.1)
            
            self.pos.add_(total_force * Config.PHYSICS_DT)
            
            # è¾¹ç•Œçº¦æŸ
            d = torch.norm(self.pos, dim=1, keepdim=True)
            mask_out = d > Config.RADIUS
            if mask_out.any():
                self.pos.masked_scatter_(mask_out, self.pos * (Config.RADIUS / (d + 1e-5)))

    def map_input(self, img_batch):
        """
        å°†å›¾åƒ (B, 1, 28, 28) æ˜ å°„åˆ° Input Nodes (N_in)
        """
        B = img_batch.shape[0]
        input_pos = self.pos[self.input_idx] # (N_in, 2)
        
        # å½’ä¸€åŒ–è¾“å…¥èŠ‚ç‚¹åæ ‡åˆ° [-1, 1]
        # ç®€å•å½’ä¸€åŒ–ï¼šå‡è®¾è¾“å…¥åŒºåœ¨å·¦ä¾§åŠåœ†
        norm_pos = input_pos.clone()
        norm_pos[:, 0] = (norm_pos[:, 0] + Config.RADIUS * 0.5) / (Config.RADIUS * 0.5)
        norm_pos[:, 1] = norm_pos[:, 1] / (Config.RADIUS * 0.8)
        norm_pos = torch.clamp(norm_pos, -1, 1)
        
        # Grid Sample
        grid = norm_pos.view(1, 1, -1, 2).expand(B, -1, -1, -1)
        sampled = F.grid_sample(img_batch, grid, align_corners=True) # (B, 1, 1, N_in)
        return sampled.view(B, -1)

    def forward(self, img_batch):
        """
        ä¸€æ¬¡æ€§æ¨ç†ï¼šåŸºäºè¿­ä»£ä¼ æ’­
        """
        B = img_batch.shape[0]
        N = Config.NODE_COUNT
        K = Config.NEIGHBOR_K
        
        # 1. å‡†å¤‡è¾“å…¥
        in_signals = self.map_input(img_batch)
        state = torch.zeros(B, N, device=Config.DEVICE)
        
        # 2. æ³¨å…¥è¾“å…¥
        state[:, self.input_idx] = in_signals * 3.0
        
        # 3. ç¨€ç–ä¼ æ’­ (Sparse Propagation)
        # è¿™æ˜¯ä¸€ä¸ªæ‰‹åŠ¨å±•å¼€çš„ GNN ä¼ æ’­è¿‡ç¨‹
        # state: (B, N)
        # neighbors: (N, K)
        # weights: (N, K)
        
        for _ in range(Config.PROPAGATION_STEPS):
            # Gather é‚»å±…çŠ¶æ€: (B, N, K)
            # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šæ¯ä¸ªèŠ‚ç‚¹æ”¶é›†å…¶é‚»å±…çš„ä¿¡æ¯ (Pull based)
            # éœ€è¦å°† indices æ‰©å±•åˆ° Batch ç»´åº¦
            
            # state (B, N) -> (B, N, 1)
            # indices (N, K) -> (B, N, K)
            idx_expand = self.indices.unsqueeze(0).expand(B, -1, -1)
            neighbor_vals = torch.gather(state, 1, idx_expand.reshape(B, -1)).view(B, N, K)
            
            # åŠ æƒæ±‚å’Œ
            # weights (N, K) -> (B, N, K)
            w_expand = self.weights.unsqueeze(0)
            
            # Aggregation: sum(neighbor * weight)
            agg = torch.sum(neighbor_vals * w_expand, dim=2) # (B, N)
            
            # Update + Activation + Bias
            delta = agg + self.bias
            
            # Input Clamping (Retina æŒç»­æ¥æ”¶å…‰å­)
            input_refresh = torch.zeros_like(state)
            input_refresh[:, self.input_idx] = in_signals
            
            # Residual update
            new_state = state + delta + input_refresh * 0.5
            
            # LayerNorm (Stability)
            mean = new_state.mean(dim=1, keepdim=True)
            std = new_state.std(dim=1, keepdim=True) + 1e-5
            state = torch.tanh((new_state - mean) / std)
            
        return state[:, self.output_idx]

# ==========================================
# 3. è®­ç»ƒä¸æ¸²æŸ“çº¿ç¨‹ (Threading Logic)
# ==========================================
class TrainingEngine:
    def __init__(self, viz_queue):
        self.model = SparseSNN().to(Config.DEVICE)
        self.viz_queue = viz_queue
        self.is_running = False
        
    def start(self):
        self.is_running = True
        threading.Thread(target=self._loop, daemon=True).start()
        
    def _loop(self):
        # æ•°æ®é›†
        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.13,), (0.3,))])
        ds = datasets.MNIST('./data', train=True, download=True, transform=transform)
        loader = torch.utils.data.DataLoader(ds, batch_size=Config.BATCH_SIZE, shuffle=True)
        
        opt = optim.Adam(self.model.parameters(), lr=Config.LR)
        crit = nn.CrossEntropyLoss()
        
        for epoch in range(Config.EPOCHS):
            if not self.is_running: break
            
            # --- é˜¶æ®µ A: ç‰©ç†ä¸æ‹“æ‰‘æ›´æ–° (CPU/GPU æ··åˆ) ---
            # 1. ç‰©ç†å¾®è°ƒ (æ¯ Epoch å¤šæ¬¡ï¼Œä¿è¯å¹³æ»‘)
            for _ in range(5): 
                self.model.physics_step()
                
            # 2. æ‹“æ‰‘é‡ç»„ (æ¯ 2 Epoch ä¸€æ¬¡ï¼Œé˜²æ­¢çªå˜)
            if epoch % 2 == 0:
                self.model.update_topology()
            
            # --- é˜¶æ®µ B: å‘é€æ¸²æŸ“æ•°æ® ---
            # ä»…ä»…ç¼“å­˜å¿…è¦çš„æ•°æ®åˆ° CPUï¼Œå‡å°‘ä¼ è¾“å¼€é”€
            with torch.no_grad():
                viz_data = {
                    'pos': self.model.pos.cpu().numpy(),
                    'indices': self.model.indices.cpu().numpy(),
                    'weights': self.model.weights.cpu().numpy(),
                    'epoch': epoch
                }
                # æ”¾å…¥é˜Ÿåˆ— (å¦‚æœæ»¡äº†å°±æ‰”æ‰æ—§çš„ï¼Œä¿è¯å®æ—¶æ€§)
                if self.viz_queue.full():
                    try: self.viz_queue.get_nowait()
                    except: pass
                self.viz_queue.put(viz_data)
            
            # --- é˜¶æ®µ C: æ¢¯åº¦ä¸‹é™ ---
            loss_acc = 0
            for b_idx, (data, target) in enumerate(loader):
                if not self.is_running: break
                
                data, target = data.to(Config.DEVICE), target.to(Config.DEVICE)
                opt.zero_grad()
                out = self.model(data)
                loss = crit(out, target)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
                opt.step()
                loss_acc += loss.item()
            
            print(f"Epoch {epoch} | Loss: {loss_acc/len(loader):.4f}")
            
        # Save
        torch.save(self.model.state_dict(), os.path.join(Config.SAVE_DIR, Config.MODEL_NAME))

    def predict(self, img_tensor):
        self.model.eval()
        with torch.no_grad():
            # éœ€è¦åœ¨ä¸»çº¿ç¨‹/æ¨ç†çº¿ç¨‹è°ƒç”¨ Forward
            # è¿™é‡Œçš„ model æ˜¯åœ¨ GPU ä¸Šçš„
            return self.model(img_tensor.to(Config.DEVICE)).cpu()

# ==========================================
# 4. äº¤äº’ç•Œé¢ (Non-blocking GUI)
# ==========================================
class App(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("High-Performance Sparse SNN")
        self.geometry("1400x900")
        self.configure(bg="#111")
        
        self.viz_queue = queue.Queue(maxsize=2)
        self.engine = TrainingEngine(self.viz_queue)
        
        self._setup_ui()
        self._setup_plot()
        
        # å¯åŠ¨å®šæ—¶å™¨è¿›è¡Œæ¸²æŸ“æ¶ˆè´¹
        self.after(30, self._consume_viz_queue)
        
    def _setup_ui(self):
        pnl = tk.Frame(self, width=300, bg="#222")
        pnl.pack(side=tk.LEFT, fill=tk.Y)
        
        tk.Label(pnl, text="Input", fg="#888", bg="#222").pack(pady=5)
        
        self.cv = tk.Canvas(pnl, width=224, height=224, bg="black", highlightthickness=0)
        self.cv.pack(pady=5)
        self.cv.bind("<B1-Motion>", self._draw)
        self.img = Image.new("L", (28, 28), 0)
        self.draw = ImageDraw.Draw(self.img)
        
        tk.Button(pnl, text="Clear", command=self._clear).pack(fill=tk.X, padx=5, pady=2)
        tk.Button(pnl, text="Start Training", command=self.engine.start, bg="#005500", fg="white").pack(fill=tk.X, padx=5, pady=10)
        
        self.lbl_pred = tk.Label(pnl, text="?", font=("Arial", 60), fg=Config.COLOR_OUT, bg="#222")
        self.lbl_pred.pack(side=tk.BOTTOM, pady=30)
        
        # ç»‘å®šæ¾å¼€é¼ æ ‡è¿›è¡Œå³æ—¶æ¨ç†
        self.cv.bind("<ButtonRelease-1>", self._infer)

    def _setup_plot(self):
        self.fig, self.ax = plt.subplots(figsize=(10, 8))
        self.fig.patch.set_facecolor(Config.THEME_BG)
        self.ax.set_facecolor(Config.THEME_BG)
        self.ax.axis('off')
        
        # é¢„åˆ›å»ºå›¾å½¢å¯¹è±¡ä»¥ä¾› update
        self.scat = self.ax.scatter([], [], s=10, c=Config.COLOR_NODE, edgecolors='none', zorder=10)
        self.lc = LineCollection([], linewidths=0.5, cmap='plasma', alpha=0.6)
        self.ax.add_collection(self.lc)
        
        self.ax.set_xlim(-Config.RADIUS*1.1, Config.RADIUS*1.1)
        self.ax.set_ylim(-Config.RADIUS*1.1, Config.RADIUS*1.1)
        
        self.canvas_agg = FigureCanvasTkAgg(self.fig, master=self)
        self.canvas_agg.get_tk_widget().pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)

    def _consume_viz_queue(self):
        """
        ä»é˜Ÿåˆ—å–æ•°æ®å¹¶æ¸²æŸ“ã€‚å¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼Œè·³è¿‡ã€‚
        è¿™ä¿è¯äº† UI æ°¸è¿œä¸å¡é¡¿ï¼Œå³ä½¿è®­ç»ƒå¾ˆæ…¢ã€‚
        """
        try:
            # éé˜»å¡è·å–
            data = self.viz_queue.get_nowait()
            self._render_frame(data)
        except queue.Empty:
            pass
        
        # 30ms åå†æ¬¡è°ƒç”¨ (çº¦ 30 FPS)
        self.after(30, self._consume_viz_queue)

    def _render_frame(self, data):
        pos = data['pos']
        indices = data['indices']
        weights = data['weights']
        
        # 1. æ›´æ–°èŠ‚ç‚¹
        self.scat.set_offsets(pos)
        
        # 2. æ›´æ–°è¿çº¿ (Sparse -> Lines)
        # ä¸ºäº†æ€§èƒ½ï¼Œæˆ‘ä»¬åªç»˜åˆ¶æƒé‡æœ€å¤§çš„å‰ 20% çš„çº¿ï¼Œæˆ–è€…è®¾å®šé˜ˆå€¼
        # æ„é€ çº¿æ®µæ•°æ® (N * K, 2, 2)
        N, K = indices.shape
        
        # è¿‡æ»¤å¼±è¿æ¥ä»¥åŠ é€Ÿæ¸²æŸ“
        mask = np.abs(weights) > 0.05
        
        # è·å–æºç‚¹å’Œç›®æ ‡ç‚¹
        # src: (N, 1) -> (N, K)
        # dst: indices
        valid_src, valid_k = np.where(mask) # Indices where weight is strong
        valid_dst = indices[valid_src, valid_k]
        
        if len(valid_src) > 0:
            p1 = pos[valid_src]
            p2 = pos[valid_dst]
            segs = np.stack((p1, p2), axis=1)
            
            self.lc.set_segments(segs)
            # é¢œè‰²æ˜ å°„æƒé‡
            w_vals = np.abs(weights[valid_src, valid_k])
            self.lc.set_array(w_vals)
        else:
            self.lc.set_segments([])
            
        self.canvas_agg.draw_idle() # ä½¿ç”¨ draw_idle ä¼˜åŒ–æ€§èƒ½

    def _draw(self, e):
        s = 28/224
        x, y = e.x*s, e.y*s
        self.draw.ellipse([x-1.5, y-1.5, x+1.5, y+1.5], fill=255)
        self.cv.create_oval(e.x-8, e.y-8, e.x+8, e.y+8, fill="white", outline="white")

    def _clear(self):
        self.cv.delete("all")
        self.img = Image.new("L", (28, 28), 0)
        self.draw = ImageDraw.Draw(self.img)
        self.lbl_pred.config(text="?")

    def _infer(self, event=None):
        """ç«‹å³æ¨ç†"""
        arr = np.array(self.img, dtype=np.float32) / 255.0
        arr = (arr - 0.13) / 0.3
        t = torch.tensor(arr).view(1, 1, 28, 28)
        
        # è°ƒç”¨æ¨ç†
        res = self.engine.predict(t) # (1, 10)
        pred = torch.argmax(res).item()
        self.lbl_pred.config(text=str(pred))

if __name__ == "__main__":
    app = App()
    app.mainloop()